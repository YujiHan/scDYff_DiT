{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanyuji/miniconda3/envs/DYffusion/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-03 23:47:57,898\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-06-03 23:47:58,018\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.stats import wasserstein_distance\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import warnings\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "import sys\n",
    "from os.path import join\n",
    "from IPython.display import display\n",
    "\n",
    "from model.stDiff_model import DiT_stDiff\n",
    "from model.stDiff_scheduler import NoiseScheduler\n",
    "from model.stDiff_train import normal_train_stDiff\n",
    "from model.sample import sample_stDiff\n",
    "from process.result_analysis import clustering_metrics\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "from process.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess\n",
    "For scRNA-seq data, data enhancement is first performed, then standard preprocessing of normalize_total and log1p is required, and finally normalization is also required. \\\n",
    "ST data requires standard preprocessing and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******** preprocess ********\n",
    "adata_spatial = sc.read_h5ad('datasets/sp/' + 'dataset2_spatial_33.h5ad')\n",
    "adata_seq = sc.read_h5ad('datasets/sc/'+ 'dataset2_seq_33.h5ad')\n",
    "\n",
    "adata_seq2 = data_augment(adata_seq.copy(), True, noise_std=10)\n",
    "adata_spatial2 = adata_spatial.copy()\n",
    "\n",
    "sc.pp.normalize_total(adata_seq2, target_sum=1e4)\n",
    "sc.pp.log1p(adata_seq2)\n",
    "adata_seq2 = scale(adata_seq2) # stDiff need\n",
    "data_seq_array = adata_seq2.X\n",
    "\n",
    "sc.pp.normalize_total(adata_spatial2, target_sum=1e4)\n",
    "sc.pp.log1p(adata_spatial2)\n",
    "adata_spatial2 = scale(adata_spatial2)\n",
    "data_spatial_array = adata_spatial2.X\n",
    "\n",
    "sp_genes = np.array(adata_spatial.var_names)\n",
    "sp_data = pd.DataFrame(data=data_spatial_array, columns=sp_genes)\n",
    "sc_data = pd.DataFrame(data=data_seq_array, columns=sp_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_seq_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## method\n",
    "In this example, we mask out some genes in the ST data and then complete them. \\\n",
    "If you target the actual missing genes, just set the mask according to the position of the missing gene. \\\n",
    "Before ST data complementation for missing genes, the corresponding complete scRNA-seq data need to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/900 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "indices should be either on cpu or on the same device as the indexed tensor (cpu)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(save_path_prefix):\n\u001b[0;32m---> 68\u001b[0m     \u001b[43mnormal_train_stDiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdiffusion_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiffusion_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mpred_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnoise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), save_path_prefix)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/sdb/hanyuji/Workbench/DYffusion/stDiff/model/stDiff_train.py:65\u001b[0m, in \u001b[0;36mnormal_train_stDiff\u001b[0;34m(model, dataloader, lr, num_epoch, pred_type, diffusion_step, device, is_tqdm, is_tune, mask)\u001b[0m\n\u001b[1;32m     62\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     63\u001b[0m timesteps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, diffusion_step, (x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],))\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m---> 65\u001b[0m x_t \u001b[38;5;241m=\u001b[39m \u001b[43mnoise_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimesteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(mask)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     70\u001b[0m x_noisy \u001b[38;5;241m=\u001b[39m x_t \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m mask) \u001b[38;5;241m+\u001b[39m x \u001b[38;5;241m*\u001b[39m mask\n",
      "File \u001b[0;32m/mnt/sdb/hanyuji/Workbench/DYffusion/stDiff/model/stDiff_scheduler.py:143\u001b[0m, in \u001b[0;36mNoiseScheduler.add_noise\u001b[0;34m(self, x_start, x_noise, timesteps)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_noise\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_start, x_noise, timesteps):  \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# input x_0,noise,t , output x_t\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     s1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt_alphas_cumprod\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    144\u001b[0m     s2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqrt_one_minus_alphas_cumprod[timesteps]\n\u001b[1;32m    146\u001b[0m     s1 \u001b[38;5;241m=\u001b[39m s1\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(x_start\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: indices should be either on cpu or on the same device as the indexed tensor (cpu)"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = 0.00016046744893538737 \n",
    "depth = 6 \n",
    "num_epoch = 900 \n",
    "diffusion_step = 1500 \n",
    "batch_size = 2048 \n",
    "hidden_size = 512 \n",
    "head = 16\n",
    "\n",
    "# mask\n",
    "cell_num = data_spatial_array.shape[0]\n",
    "gene_num = data_spatial_array.shape[1]\n",
    "mask = np.ones((gene_num,), dtype='float32')\n",
    "\n",
    "# gene_id_test\n",
    "train_size = 0.8\n",
    "gene_names_rnaseq = sp_genes \n",
    "np.random.seed(0)\n",
    "n_genes = len(gene_names_rnaseq)\n",
    "gene_ids_train = sorted(\n",
    "    np.random.choice(range(n_genes), int(n_genes * train_size), False)\n",
    ")\n",
    "gene_ids_test = sorted(set(range(n_genes)) - set(gene_ids_train)) # test\n",
    "\n",
    "mask[gene_ids_test] = 0\n",
    "\n",
    "seq = data_seq_array\n",
    "st = data_spatial_array\n",
    "data_seq_masked = seq * mask\n",
    "data_spatial_masked = st * mask\n",
    "\n",
    "seq = seq * 2 - 1\n",
    "data_seq_masked = data_seq_masked * 2 - 1\n",
    "\n",
    "st = st * 2 - 1\n",
    "data_spatial_masked = data_spatial_masked * 2 - 1\n",
    "\n",
    "dataloader = get_data_loader(\n",
    "    seq, # all gene\n",
    "    data_seq_masked, # test gene = 0\n",
    "    batch_size=batch_size, \n",
    "    is_shuffle=True)\n",
    "\n",
    "seed = 1202\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "model = DiT_stDiff(\n",
    "    input_size=gene_num,  \n",
    "    hidden_size=hidden_size, \n",
    "    depth=depth,\n",
    "    num_heads=head,\n",
    "    classes=6, \n",
    "    mlp_ratio=4.0,\n",
    "    dit_type='dit'\n",
    ")\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "model.to(device)\n",
    "\n",
    "diffusion_step = diffusion_step\n",
    "\n",
    "save_path_prefix = 'ckpt/demo.pt'\n",
    "# train\n",
    "model.train()\n",
    "if not os.path.isfile(save_path_prefix):\n",
    "\n",
    "    normal_train_stDiff(model,\n",
    "                            dataloader=dataloader,\n",
    "                            lr=lr,\n",
    "                            num_epoch=num_epoch,\n",
    "                            diffusion_step=diffusion_step,\n",
    "                            device=device,\n",
    "                            pred_type='noise',\n",
    "                            mask=mask)\n",
    "\n",
    "    torch.save(model.state_dict(), save_path_prefix)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(save_path_prefix))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time: 0: 100%|██████████| 1500/1500 [01:53<00:00, 13.25it/s]  \n"
     ]
    }
   ],
   "source": [
    "# sample\n",
    "gt = data_spatial_masked\n",
    "noise_scheduler = NoiseScheduler(\n",
    "    num_timesteps=diffusion_step,\n",
    "    beta_schedule='cosine'\n",
    ")\n",
    "\n",
    "dataloader = get_data_loader(\n",
    "    data_spatial_masked, # test gene = 0\n",
    "    data_spatial_masked, # test gene = 0\n",
    "    batch_size=batch_size, \n",
    "    is_shuffle=False)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "imputation = sample_stDiff(model,\n",
    "                                    device=device,\n",
    "                                    dataloader=dataloader,\n",
    "                                    noise_scheduler=noise_scheduler,\n",
    "                                    mask=mask,\n",
    "                                    gt=gt,\n",
    "                                    num_step=diffusion_step,\n",
    "                                    sample_shape=(cell_num, gene_num),\n",
    "                                    is_condi=True,\n",
    "                                    sample_intermediate=diffusion_step,\n",
    "                                    model_pred_type='noise',\n",
    "                                    is_classifier_guidance=False,\n",
    "                                    omega=0.2)\n",
    "\n",
    "data_spatial_masked[:, gene_ids_test] = imputation[:, gene_ids_test]\n",
    "\n",
    "impu = (data_spatial_masked  + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3104034168196477"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ********** metrics **********\n",
    "def imputation_metrics(original, imputed):\n",
    "    absolute_error = np.abs(original - imputed)\n",
    "    relative_error = absolute_error / np.maximum(\n",
    "        np.abs(original), np.ones_like(original)\n",
    "    )\n",
    "    spearman_gene = []\n",
    "    for g in range(imputed.shape[1]):\n",
    "        if np.all(imputed[:, g] == 0):\n",
    "            correlation = 0\n",
    "        else:\n",
    "            correlation = spearmanr(original[:, g], imputed[:, g])[0]\n",
    "        spearman_gene.append(correlation)\n",
    "\n",
    "    return {\n",
    "        \"median_absolute_error_per_gene\": np.median(absolute_error, axis=0),\n",
    "        \"mean_absolute_error_per_gene\": np.mean(absolute_error, axis=0),\n",
    "        \"mean_relative_error\": np.mean(relative_error, axis=1),\n",
    "        \"median_relative_error\": np.median(relative_error, axis=1),\n",
    "        \"spearman_per_gene\": np.array(spearman_gene),\n",
    "\n",
    "        # Metric we report in the GimVI paper:\n",
    "        \"median_spearman_per_gene\": np.median(spearman_gene),\n",
    "    }\n",
    "\n",
    "tmp = imputation_metrics(np.array(data_spatial_array[:, gene_ids_test]), impu[:, gene_ids_test])\n",
    "tmp['median_spearman_per_gene']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stDiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "\n",
    "from simple_Linear_model import simple_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = torch.Tensor(np.random.random((32,40)))\n",
    "# t = torch.Tensor(np.ones((1,)))\n",
    "\n",
    "model = simple_linear(input_size=50,output_size=50,hidden_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/hanyuji/Results/VAE_result/DR_latent_50.pkl'\n",
    "\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    data_list = pickle.load(f)\n",
    "\n",
    "label_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CombinationDataloader(data_list, label_list):\n",
    "    combinations = []  # 存储所有可能的三点组合\n",
    "    combinations_label = []\n",
    "\n",
    "    # 生成所有可能的三点组合\n",
    "    for i in range(len(data_list)):\n",
    "        for j in range(i + 1, len(data_list)):\n",
    "            for k in range(j + 1, len(data_list)):\n",
    "                combinations.append((data_list[i], data_list[j], data_list[k]))\n",
    "                combinations_label.append((label_list[i], label_list[j], label_list[k]))\n",
    "\n",
    "    return (combinations, combinations_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations, combinations_label = CombinationDataloader(data_list,label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda:1')\n",
    "num_epoch = 30\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 30/30 [00:27<00:00,  1.10it/s, loss:0.96842]\n"
     ]
    }
   ],
   "source": [
    "input_size = 50\n",
    "batch_size = 256\n",
    "\n",
    "t_epoch = tqdm(range(num_epoch), ncols=100)\n",
    "\n",
    "model.train()\n",
    "for epoch in t_epoch:\n",
    "    epoch_loss = 0.0\n",
    "    for i, (c, l) in enumerate(zip(combinations, combinations_label)):\n",
    "\n",
    "        c0, c1, c2 = c[0], c[1], c[2]\n",
    "        \n",
    "        cell_idx_0 = np.random.choice(np.arange(c0.shape[0]), size = batch_size, replace = (c0.shape[0] < batch_size))\n",
    "        cell_idx_1 = np.random.choice(np.arange(c1.shape[0]), size = batch_size, replace = (c1.shape[0] < batch_size))\n",
    "        cell_idx_2 = np.random.choice(np.arange(c2.shape[0]), size = batch_size, replace = (c2.shape[0] < batch_size))\n",
    "        c0 = c0[cell_idx_0, :]\n",
    "        c1 = c1[cell_idx_1, :]\n",
    "        c2 = c2[cell_idx_2, :]\n",
    "        \n",
    "        \n",
    "        x1, x2, x3 = (\n",
    "            torch.tensor(c0).type(torch.float32).to(device),\n",
    "            torch.tensor(c1).type(torch.float32).to(device),\n",
    "            torch.tensor(c2).type(torch.float32).to(device),\n",
    "        )\n",
    "        t1, t2, t3 = (\n",
    "            torch.tensor(np.full(input_size, l[0])).type(torch.float32).to(device),\n",
    "            torch.tensor(np.full(input_size, l[1])).type(torch.float32).to(device),\n",
    "            torch.tensor(np.full(input_size, l[2])).type(torch.float32).to(device),\n",
    "        )\n",
    "\n",
    "       \n",
    "        x2_pred = model(x1, x3, t1, t2, t3)\n",
    "\n",
    "        loss = criterion(x2, x2_pred)\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # type: ignore\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss = epoch_loss / (i + 1)  # type: ignore\n",
    "\n",
    "    t_epoch.set_postfix_str(f'loss:{epoch_loss:.5f}')  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SinkhornLoss(true_obs, est_obs, blur=0.05, scaling=0.5, batch_size=None):\n",
    "    '''\n",
    "    Wasserstein distance computed by Sinkhorn algorithm.\n",
    "    :param true_obs (torch.FloatTensor): True expression data.\n",
    "    :param est_obs (torch.FloatTensor): Predicted expression data.\n",
    "    :param blur (float): Sinkhorn algorithm hyperparameter. Default as 0.05.\n",
    "    :param scaling (float): Sinkhorn algorithm hyperparameter. Default as 0.5.\n",
    "    :param batch_size (None or int): Either None indicates using all true cell in computation, or an integer indicates\n",
    "                                     using only a batch of true cells to save computational costs.\n",
    "    :return: (float) Wasserstein distance average over all timepoints.\n",
    "    '''\n",
    "    n_tps = len(true_obs)\n",
    "    loss = 0.0\n",
    "    ot_solver = geomloss.SamplesLoss(\"sinkhorn\", p=2, blur=blur, scaling=scaling, debias=True, backend=\"tensorized\")\n",
    "    for t in range(n_tps):\n",
    "        t_est = est_obs[:, t, :]\n",
    "        t_true = true_obs[t]\n",
    "        if batch_size is not None:\n",
    "            cell_idx = np.random.choice(np.arange(t_true.shape[0]), size = batch_size, replace = (t_true.shape[0] < batch_size))\n",
    "            t_true = t_true[cell_idx, :]\n",
    "        t_loss = ot_solver(t_true, t_est)\n",
    "        loss += t_loss\n",
    "    loss = loss / n_tps\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DYffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

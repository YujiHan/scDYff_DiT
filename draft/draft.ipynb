{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "\n",
    "from simple_Linear_model import simple_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/hanyuji/Results/VAE_result/DR_latent_50.pkl'\n",
    "\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    data_list = pickle.load(f)\n",
    "\n",
    "label_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CombinationDataloader(data_list, label_list):\n",
    "    combinations = []  # 存储所有可能的三点组合\n",
    "    combinations_label = []\n",
    "\n",
    "    # 生成所有可能的三点组合\n",
    "    for i in range(len(data_list)):\n",
    "        for j in range(i + 1, len(data_list)):\n",
    "            for k in range(j + 1, len(data_list)):\n",
    "                combinations.append((data_list[i], data_list[j], data_list[k]))\n",
    "                combinations_label.append((label_list[i], label_list[j], label_list[k]))\n",
    "\n",
    "    return (combinations, combinations_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations, combinations_label = CombinationDataloader(data_list,label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "for i, (c, l) in enumerate(zip(combinations, combinations_label)):\n",
    "\n",
    "    c0, c1, c2 = c[0], c[1], c[2]\n",
    "    \n",
    "    cell_idx_0 = np.random.choice(np.arange(c0.shape[0]), size = batch_size, replace = (c0.shape[0] < batch_size))\n",
    "    cell_idx_1 = np.random.choice(np.arange(c1.shape[0]), size = batch_size, replace = (c1.shape[0] < batch_size))\n",
    "    cell_idx_2 = np.random.choice(np.arange(c2.shape[0]), size = batch_size, replace = (c2.shape[0] < batch_size))\n",
    "    c0 = c0[cell_idx_0, :]\n",
    "    c1 = c1[cell_idx_1, :]\n",
    "    c2 = c2[cell_idx_2, :]\n",
    "    \n",
    "    x02 = np.concatenate([c0, c2], axis=1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x02.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 50)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DYffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
